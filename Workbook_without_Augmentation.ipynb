{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Workbook without Augmentation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stereo-Alex/Frutavision/blob/main/Workbook_without_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0aSPvIj4ApD"
      },
      "source": [
        "# Connecting to the kaggle api and downloading the data "
      ],
      "id": "w0aSPvIj4ApD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzVOMlCj0pRL"
      },
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "id": "OzVOMlCj0pRL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1SqXs0i3fJ4"
      },
      "source": [
        "!kaggle datasets download -d chrisfilo/fruit-recognition"
      ],
      "id": "a1SqXs0i3fJ4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCdp1nIo4Noq"
      },
      "source": [
        "## Creating directories and unziping the data into the directories"
      ],
      "id": "zCdp1nIo4Noq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acMgGzs5hbFf"
      },
      "source": [
        "!mkdir fruit\n",
        "!unzip fruit-recognition.zip -d fruit\n"
      ],
      "id": "acMgGzs5hbFf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "affiliated-bernard"
      },
      "source": [
        "# Creating a df with the paths"
      ],
      "id": "affiliated-bernard"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lesser-installation"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "lesser-installation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoTeEwa8mxbQ"
      },
      "source": [
        "data_folder = '/content/fruit/'\n",
        "paths = os.listdir(data_folder)\n",
        "os.path.join(data_folder, paths[0])\n",
        "list_of_paths = [os.path.join(data_folder, x) for x in paths]\n",
        "list_of_paths"
      ],
      "id": "zoTeEwa8mxbQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "accomplished-founder"
      },
      "source": [
        "list_of_paths[0]"
      ],
      "id": "accomplished-founder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "overall-polymer"
      },
      "source": [
        "def data_frame_gen(list_of_paths):\n",
        "    all_files = []\n",
        "    for path in list_of_paths:\n",
        "        \n",
        "        for dirpath, _, filenames in os.walk(path):\n",
        "            for fn in filenames:\n",
        "                all_files.append(os.path.join(dirpath, fn))\n",
        "    \n",
        "    img_df = pd.DataFrame({'Path': all_files})\n",
        "    \n",
        "    img_df['Fruit'] = img_df['Path'].apply(lambda p: p.split(os.sep)[3])\n",
        "    img_df = img_df[['Fruit', 'Path']]            \n",
        "    \n",
        "    return img_df\n"
      ],
      "id": "overall-polymer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "major-cameroon"
      },
      "source": [
        "df = data_frame_gen(list_of_paths)"
      ],
      "id": "major-cameroon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soviet-mirror"
      },
      "source": [
        "df.shape"
      ],
      "id": "soviet-mirror",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hungarian-tamil"
      },
      "source": [
        "df"
      ],
      "id": "hungarian-tamil",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "excessive-dover"
      },
      "source": [
        "## Removing DS_store\n",
        "\n",
        "for path in df.Path:\n",
        "    count_to_drop = 0 \n",
        "    if 'DS_Store'in str(path):\n",
        "        df = df.drop(df.index[count_to_drop])\n",
        "    count_to_drop = count_to_drop + 1\n",
        "        "
      ],
      "id": "excessive-dover",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neutral-jason"
      },
      "source": [
        "df.groupby('Fruit').count()\n"
      ],
      "id": "neutral-jason",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f4mp-ks8CSO"
      },
      "source": [
        "img = cv2.imread(df['Path'][1], cv2.COLOR_BGR2RGB)\n",
        "img_GRB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img_GRB)\n",
        "#print(img_GRB)\n",
        "plt.show()"
      ],
      "id": "8f4mp-ks8CSO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opponent-government"
      },
      "source": [
        "## Preping the data "
      ],
      "id": "opponent-government"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "processed-shaft"
      },
      "source": [
        "# adding a label to the data \n",
        "\n",
        "fruit_names = sorted(df.Fruit.unique())\n",
        "mapper_fruit_names = dict(zip(fruit_names, [t for t in range(len(fruit_names))]))\n",
        "df[\"label\"] = df[\"Fruit\"].map(mapper_fruit_names)\n",
        "print(mapper_fruit_names)\n",
        "\n",
        "# Visualize the resulting dataframe\n",
        "df.head()"
      ],
      "id": "processed-shaft",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suspended-referral"
      },
      "source": [
        "# Preping to model"
      ],
      "id": "suspended-referral"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skilled-arcade"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1/255, \n",
        "                              validation_split = 0.1)\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "        '/content/fruit',  \n",
        "        target_size=(150, 150),  \n",
        "        batch_size=128,\n",
        "        class_mode='categorical',\n",
        "        subset = 'training'\n",
        "        )\n",
        "\n",
        "validation_generator = data_gen.flow_from_directory(\n",
        "        '/content/fruit',  \n",
        "        target_size=(150, 150),  \n",
        "        batch_size=128,\n",
        "        class_mode='categorical',\n",
        "        subset = 'validation'\n",
        "        )\n",
        "\n",
        "\n"
      ],
      "id": "skilled-arcade",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j3JuzeIYw1o"
      },
      "source": [
        "shape_img = (150,150,3)"
      ],
      "id": "5j3JuzeIYw1o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DJMHIAaBTrP"
      },
      "source": [
        "# Basic fine tuning parameters: \n",
        "\n",
        "epochs = 15\n",
        "loss_function = 'categorical_crossentropy'\n",
        "optimizer = 'adam'\n",
        "metrics = ['accuracy']\n",
        "\n"
      ],
      "id": "_DJMHIAaBTrP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ2usR0BBOMX"
      },
      "source": [
        "# Model\n"
      ],
      "id": "tZ2usR0BBOMX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04wpZuhQYBXB"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "  \n",
        "model =  tf.keras.models.Sequential([\n",
        "\n",
        "        tf.keras.layers.Conv2D(32 ,(3,3), activation = 'relu', input_shape = shape_img, padding = 'same'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64 ,(3,3), activation = 'relu',padding = 'same'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64 ,(3,3), activation = 'relu', padding = 'same'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64 ,(3,3), activation = 'relu', padding = 'same'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64 ,(3,3), activation = 'relu', padding = 'same'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(32 ,(3,3), activation = 'relu', padding = 'same'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(15, activation = 'softmax')\n",
        "\n",
        "                                     \n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=loss_function,\n",
        "              optimizer=optimizer,\n",
        "              metrics=metrics)"
      ],
      "id": "04wpZuhQYBXB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwLEtt1n1MjJ"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=epochs ,\n",
        "                    validation_data = validation_generator)"
      ],
      "id": "jwLEtt1n1MjJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-yEDrZ0CA8Q"
      },
      "source": [
        "# Benchmarking"
      ],
      "id": "g-yEDrZ0CA8Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YztsBva958WM"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy for 5 epochs')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "id": "YztsBva958WM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD4QXlUa0O3z"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy for 15 epochs')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "id": "uD4QXlUa0O3z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHQO1c01z83F"
      },
      "source": [
        ""
      ],
      "id": "AHQO1c01z83F",
      "execution_count": null,
      "outputs": []
    }
  ]
}